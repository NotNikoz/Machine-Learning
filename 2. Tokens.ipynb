{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgEbnPLoZlpc"
   },
   "source": [
    "# Ejercicio 1: Carga de datos desde un archivo CSV\n",
    "\n",
    "Carga el conjunto de datos llamado `textos_multiple.csv`. Este archivo contiene una columna de texto y otra de etiquetas, asociadas a cada grupo de frases. Se separa por `;` Las columnas son:\n",
    "\n",
    "- **texto:** Texto compuesto por varias oraciones.\n",
    "- **etiqueta:** Categoría asignada al grupo de oraciones (por ejemplo: deportes, política, tecnología, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BXkYWPy4Zhgr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(\"textos_multiple.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mtIC8TvZrU_"
   },
   "source": [
    "# Ejercicio 2: Mostrar las primeras filas del DataFrame\n",
    "\n",
    "Muestra las primeras 5 filas para verificar que los datos se hayan cargado correctamente. Observa cómo se presentan los textos y asegúrate de que las etiquetas estén correctamente alineadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lTnsfLB8Zr7m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               frase  etiqueta\n",
      "0  El jugador marcó un gol decisivo. El jugador f...  deportes\n",
      "1  El estadio vibró con cada gol del equipo. El e...  deportes\n",
      "2  La selección nacional ganó el partido con un r...  deportes\n",
      "3  El estadio vibró con cada gol del equipo. El e...  deportes\n",
      "4  El jugador marcó un gol decisivo. El jugador f...  deportes\n"
     ]
    }
   ],
   "source": [
    "# Ver las primeras filas para comprobar que se cargó bien\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHCIqkcrZvIu"
   },
   "source": [
    "# Ejercicio 3: Preprocesamiento básico de texto\n",
    "\n",
    "Realiza el siguiente preprocesamiento sobre la columna `texto`:\n",
    "\n",
    "- Convierte todo el texto a minúsculas.\n",
    "- Elimina signos de puntuación.\n",
    "- Tokeniza las oraciones en palabras.\n",
    "\n",
    "Muestra un ejemplo del resultado para la primera fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AmU8F9ElZwIS"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"textos_multiple.csv\", sep=\";\")\n",
    "\n",
    "def preprocesar_texto(texto):\n",
    "    # Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # Eliminar signos de puntuación (todo lo que no sea letra, número o espacio)\n",
    "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto)\n",
    "    # Tokenizar en \"palabras\" separando por espacios\n",
    "    tokens = texto.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLi_IOerZyUZ"
   },
   "source": [
    "# Ejercicio 4: Eliminación de stopwords\n",
    "\n",
    "Crea un nuevo DataFrame con la columna `texto`.\n",
    "\n",
    "Para cada frase del DataFrame:\n",
    "\n",
    "- Convierte la frase a minúsculas utilizando el método `.lower()`.\n",
    "- Divide la frase en palabras usando el método `.split()`.\n",
    "- Elimina las palabras vacías (stopwords) usando una lista de stopwords en español (puedes usar la lista de `nltk.corpus.stopwords` o definir una manualmente).\n",
    "\n",
    "Muestra el resultado de las primeras 3 filas con las stopwords eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sy3lsSj0Z2fX"
   },
   "outputs": [],
   "source": [
    "stopwords_manual = [\n",
    "'a', 'acá', 'ahí', 'ajena', 'ajeno', 'ajenos', 'al', 'algo', 'algún', 'alguna', 'algun', 'algunao', 'alguno', 'algunos', 'allá', 'alí',\n",
    "'ambos', 'ante', 'antes', 'aquel', 'aquella', 'aquello', 'aquellos', 'aquí', 'arriba', 'así', 'atrás', 'aun', 'aunque', 'bajo', 'bastante',\n",
    "'bien', 'cabe', 'cada', 'casi', 'cierto', 'cierta', 'ciertos', 'como', 'con', 'conmigo', 'conseguimos', 'conseguir', 'consigo', 'consigue',\n",
    "'consiguen', 'consigues', 'contigo', 'contra', 'cual', 'cuales', 'cualquier', 'cualquiera', 'cuan', 'cuando', 'cuanto', 'cuanta', 'cuantos',\n",
    "'de', 'dejar', 'del', 'demás', 'demasiada', 'demasiado', 'demasiados', 'dentro', 'desde', 'donde', 'dos', 'el', 'él', 'ella', 'ellos', 'empleáis',\n",
    "'emplean', 'emplear', 'empleas', 'empleo', 'en', 'encima', 'entonces', 'entre', 'era', 'eras', 'eramos', 'eran', 'eres', 'es', 'esa', 'ese', 'eso',\n",
    "'esas', 'esta', 'estas', 'estaba', 'estado', 'estáis', 'estamos', 'están', 'estar', 'este', 'estos', 'estoy', 'etc', 'fin', 'fue', 'fueron', 'fui',\n",
    "'fuimos', 'gueno', 'ha', 'hace', 'haces', 'hacéis', 'hacemos', 'hacen', 'hacer', 'hacia', 'hago', 'hasta', 'incluso', 'intenta', 'intentas', 'intentáis',\n",
    "'intentamos', 'intentan', 'intentar', 'intento', 'ir', 'jamás', 'junto', 'juntos', 'la', 'las', 'lo', 'largo', 'más', 'me', 'menos', 'mi', 'mis', 'mía',\n",
    "'mías', 'mientras', 'mío', 'míos', 'misma', 'mismo', 'mismas', 'modo', 'mucha', 'muchísima', 'muchísimo', 'mucho', 'muchos', 'muy', 'nada', 'ni', 'ningún',\n",
    "'ninguna', 'ninguno', 'ningunos', 'no', 'nos', 'nosotras', 'nosotros', 'nuestra', 'nuestro', 'nuestras', 'nuestros', 'nunca', 'os', 'otra', 'otro', 'otras',\n",
    "'para', 'parecer', 'pero', 'poca', 'pocas', 'podéis', 'podemos', 'poder', 'podría', 'podrías', 'podríais', 'podríamos', 'podrían', 'por', 'por qué', 'porque',\n",
    "'primero', 'puede', 'pueden', 'puedo', 'pues', 'que', 'qué', 'querer', 'quién', 'quiénes', 'quienesquiera', 'quienquiera', 'quizá', 'quizás', 'sabe', 'sabes',\n",
    "'sabéis', 'sabemos', 'saber', 'se', 'según', 'ser', 'si', 'sí', 'siempre', 'siendo', 'sin', 'sino', 'so', 'sobre', 'sois', 'solamente', 'solo', 'sólo', 'somos',\n",
    "'soy', 'sr', 'sra', 'sres', 'sta', 'su', 'sus', 'suya', 'suyo', 'suyos', 'tal', 'tales', 'también', 'tampoco', 'tan', 'tanta', 'tanto', 'te', 'tenéis', 'tenemos',\n",
    "'tener', 'tengo', 'ti', 'tiempo', 'tiene', 'tienen', 'toda', 'todo', 'todos', 'tomar', 'trabaja', 'trabajáis', 'trabajamos', 'trabajan', 'trabajar', 'trabajas',\n",
    "'tras', 'tú', 'tu', 'tus', 'tuya', 'tuyo', 'tuyos', 'último', 'ultimo', 'un', 'una', 'uno', 'unas', 'usa', 'usas', 'usáis', 'usamos', 'usan', 'usar', 'uso',\n",
    "\"usted\", \"ustedes\", 'va', 'van', 'vais', 'valor', 'vamos', 'varias', 'varios', 'vaya', 'verdadera', 'vosotras', 'vosotros', 'voy', 'vuestra', 'vuestro', 'vuestros',\n",
    "'y', 'ya', 'yo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VcrmNjUsZ2xU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               frase  \\\n",
      "0  El jugador marcó un gol decisivo. El jugador f...   \n",
      "1  El estadio vibró con cada gol del equipo. El e...   \n",
      "2  La selección nacional ganó el partido con un r...   \n",
      "\n",
      "                                 frase_sin_stopwords  \n",
      "0  [jugador, marcó, gol, decisivo, jugador, héroe...  \n",
      "1  [estadio, vibró, gol, equipo, equipo, aprovech...  \n",
      "2  [selección, nacional, ganó, partido, resultado...  \n"
     ]
    }
   ],
   "source": [
    "def eliminar_stopwords(texto):\n",
    "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto)  # eliminar signos de puntuación primero\n",
    "    palabras = texto.lower().split()       # luego pasar a minúsculas y dividir\n",
    "    palabras_limpias = [p for p in palabras if p not in stopwords_manual]\n",
    "    return palabras_limpias\n",
    "\n",
    "df_filtrado = df[[\"frase\"]].copy()\n",
    "df_filtrado[\"frase_sin_stopwords\"] = df_filtrado[\"frase\"].apply(eliminar_stopwords)\n",
    "print(df_filtrado.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N_dKf1wZ6HW"
   },
   "source": [
    "# Ejercicio 5: Crear el vocabulario\n",
    "\n",
    "A partir del texto preprocesado y sin stopwords, crea un vocabulario con todas las palabras únicas presentes en el corpus.\n",
    "\n",
    "Para ello:\n",
    "\n",
    "- Recorre todas las frases ya tokenizadas y limpias.\n",
    "- Extrae las palabras únicas y almacénalas en un conjunto (`set`).\n",
    "- Ordena el vocabulario alfabéticamente y conviértelo en una lista.\n",
    "\n",
    "Muestra las primeras 20 palabras del vocabulario resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kD1HlufoZ735"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXwBHWXEZ-th"
   },
   "source": [
    "# Ejercicio 6: Representación Bag-of-Words\n",
    "\n",
    "Utiliza el vocabulario creado en el ejercicio anterior para representar cada frase como un vector numérico utilizando el modelo **Bag-of-Words**.\n",
    "\n",
    "Para ello:\n",
    "\n",
    "- Crea un vector para cada frase, con tantas posiciones como palabras haya en el vocabulario.\n",
    "- Cada posición del vector debe contener la cantidad de veces que aparece esa palabra en la frase correspondiente.\n",
    "- Puedes usar una estructura como un diccionario para mapear palabras a índices.\n",
    "\n",
    "Muestra los vectores resultantes para las primeras 3 frases del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgnI7SzeZ_Ft"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuQh_l_baCQk"
   },
   "source": [
    "# Ejercicio 7: Generación de n-gramas\n",
    "\n",
    "Extiende la representación Bag-of-Words utilizando **n-gramas** en lugar de palabras individuales.\n",
    "\n",
    "Para ello:\n",
    "\n",
    "- Crea una función que, dado un valor de `n`, genere los **n-gramas** para cada frase del corpus ya preprocesado y sin stopwords.\n",
    "- Aplica esta función a cada frase con `n=2` (bigramas) y `n=3` (trigramas).\n",
    "- Crea el vocabulario de n-gramas y construye los vectores correspondientes para cada frase, tal como se hizo con palabras individuales.\n",
    "\n",
    "Muestra los bigramas generados para las primeras 2 frases y el vocabulario total de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Su9XiopeaDbe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
