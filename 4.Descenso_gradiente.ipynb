{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdTWdeQIigqD"
      },
      "source": [
        "# Descenso por gradiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YVkSGPvioMp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5vVuMG3dUEE"
      },
      "source": [
        "## Generación de datos\n",
        "\n",
        "Generamos un conjunto aleatorio de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "_f5jUIS3db0F",
        "outputId": "c0b7151f-f3c1-4efc-c055-8c4bb1f67003"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X = np.linspace(0, 10, 50)\n",
        "y = 3 * X + np.random.randn(50) * 3\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Datos\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Emu-QEddefs"
      },
      "source": [
        "## Algoritmo de descenso por gradiente\n",
        "\n",
        "Partimos de una pendiente y un intercepto de 0. También podría iniciarse con un valor aleatorio.\n",
        "\n",
        "Para cada elemento del conjunto de datos calculamos el error de su predicción teniendo en cuenta la pendiente y el intercepto.\n",
        "\n",
        "Calculamos el error y el gradiente.\n",
        "\n",
        "Actualizamos la pendiente y el intercepto.\n",
        "\n",
        "Calculamos el coste para poder mostrarlo en el historial, pero no afecta al algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dISBA1Jni3GB"
      },
      "outputs": [],
      "source": [
        "def gradiente_descendente(X, y, alpha, iteraciones):\n",
        "    # Inicializar parámetros\n",
        "    m = 0.0  # pendiente\n",
        "    b = 0.0  # intercepto\n",
        "\n",
        "    n = len(X)\n",
        "    historial_coste = []\n",
        "\n",
        "    for i in range(iteraciones):\n",
        "        # Predicciones\n",
        "        y_pred = m * X + b\n",
        "\n",
        "        # Cálculo del error\n",
        "        error = y_pred - y\n",
        "\n",
        "        # Gradientes\n",
        "        dm = (2/n) * np.dot(error, X)\n",
        "        db = (2/n) * np.sum(error)\n",
        "\n",
        "        # Actualización de parámetros\n",
        "        m -= alpha * dm\n",
        "        b -= alpha * db\n",
        "\n",
        "        # Calcular coste (MSE)\n",
        "        coste = (1/n) * np.sum((y - y_pred)**2)\n",
        "        historial_coste.append(coste)\n",
        "\n",
        "    return m, b, historial_coste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9u3eo-KeFTf"
      },
      "source": [
        "## Ejecutamos el algoritmo\n",
        "\n",
        "Para cada tasa de aprendizaje lanzamos el algoritmo y mostramos el comportamiento de su coste.\n",
        "\n",
        "Puedes probar con diferentes tasas a ver que pasa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kx5oXp5ji6se",
        "outputId": "000ba241-09af-44de-cc1b-613a532e31ce"
      },
      "outputs": [],
      "source": [
        "tasa_aprendizaje = [0.000001,0.00001]\n",
        "iteraciones = 100\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for alpha in tasa_aprendizaje:\n",
        "    m, b, historial = gradiente_descendente(X, y, alpha, iteraciones)\n",
        "    plt.plot(historial, label=f\"alpha={alpha}\")\n",
        "\n",
        "plt.xlabel(\"Iteraciones\")\n",
        "plt.ylabel(\"Coste (MSE)\")\n",
        "plt.ylim(0, 1000)\n",
        "plt.title(\"Evolución del coste para distintas tasas de aprendizaje\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
